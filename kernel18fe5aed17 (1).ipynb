{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\n",
    "annotations=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\")\n",
    "train=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\n",
    "submission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating directories for train and validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/images\n",
    "!mkdir /kaggle/working/images/train\n",
    "!mkdir /kaggle/working/images/validation\n",
    "!mkdir /kaggle/working/images/train/face_with_mask\n",
    "!mkdir /kaggle/working/images/train/face_no_mask\n",
    "!mkdir /kaggle/working/images/validation/face_with_mask\n",
    "!mkdir /kaggle/working/images/validation/face_no_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting only images having class as face mask or face_no_mask and ignoring other classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/\"\n",
    "train=\"/kaggle/working/images/train/face_with_mask/\"\n",
    "train_1=\"/kaggle/working/images/train/face_no_mask/\"\n",
    "\n",
    "test=\"/kaggle/working/images/validation/face_with_mask/\"\n",
    "test_1=\"/kaggle/working/images/validation/face_no_mask/\"\n",
    "\n",
    "count=0\n",
    "with open('/kaggle/input/face-mask-detection-dataset/train.csv') as csvfile:\n",
    "    readCSV = list(csv.reader(csvfile, delimiter=','))\n",
    "    print(len([row for row in readCSV[1:] if(row[5]==\"face_with_mask\" or row[5]==\"face_no_mask\")]))\n",
    "    len_train_samples=int(len([row for row in readCSV[1:] if(row[5]==\"face_with_mask\" or row[5]==\"face_no_mask\")])*0.7)\n",
    "    for row in readCSV[1:]:\n",
    "        if(row[5]==\"face_with_mask\" or row[5]==\"face_no_mask\"):\n",
    "            count+=1\n",
    "            x1=int(row[1])\n",
    "            x2=int(row[2])\n",
    "            y1=int(row[3])\n",
    "            y2=int(row[4])\n",
    "            \n",
    "            image=cv2.imread(src_path+row[0])\n",
    "            image=image[x2:y2,x1:y1]\n",
    "            \n",
    "            if(count<=len_train_samples and row[5]==\"face_with_mask\"):\n",
    "                cv2.imwrite(train+str(count)+\".jpg\",image)\n",
    "            \n",
    "            elif(count<=len_train_samples and row[5]==\"face_no_mask\"):\n",
    "                cv2.imwrite(train_1+str(count)+\".jpg\",image)\n",
    "            \n",
    "            elif(count>len_train_samples and row[5]==\"face_with_mask\"):\n",
    "                cv2.imwrite(test+str(count)+\".jpg\",image)\n",
    "            \n",
    "            elif(count>len_train_samples and row[5]==\"face_no_mask\"):\n",
    "                cv2.imwrite(test_1+str(count)+\".jpg\",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model framework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = tf.keras.models.Sequential([    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image augamentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"/kaggle/working/images/train/\"\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(training_dir, batch_size=5, class_mode='binary', target_size=(150, 150))\n",
    "\n",
    "validation_dir = \"/kaggle/working/images/validation/\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, batch_size=5, class_mode='binary',target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The below model results into approx 90% training and 89% cv accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, epochs=20, verbose=1, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rZEUlbhDe6S",
    "outputId": "a22f0bbe-b887-438c-b1e3-c1d3dbd3a69f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "img = mpimg.imread('/content/unzipped/Medical mask/Medical Mask/images/0001.jpg')\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using mtcnn to detect faces for inputting to the model for predictions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1PUrBq3ELBz",
    "outputId": "f37d3c7a-fd92-4bf6-b29c-7aef743229bb"
   },
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ttljna7gEn6L",
    "outputId": "5ebf7d8f-818d-415e-dab3-1a3a5059acc6"
   },
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZnNAmIbkjvZ"
   },
   "source": [
    "**Test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGgLe2tpE5Qe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "images_dir='/content/unzipped/Medical mask/Medical Mask/images'\n",
    "a = os.listdir(images_dir)\n",
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0v08K-HDFMZZ",
    "outputId": "ca0d3a7a-8a23-4721-f1aa-a401b9f4041c"
   },
   "outputs": [],
   "source": [
    "test_images = a[:1800]\n",
    "len(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp_qu8OQkrRS"
   },
   "source": [
    "**Detecting faces for text images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSuA29K6FTJW"
   },
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "test_df = []\n",
    "for image in test_images:\n",
    "    img = plt.imread(os.path.join(images_dir, image))\n",
    "    faces = detector.detect_faces(img)\n",
    "    test = []\n",
    "    for face in faces:\n",
    "        bounding_box = face['box']\n",
    "        a=bounding_box[0]\n",
    "        b=bounding_box[1]\n",
    "        c=bounding_box[2]\n",
    "        d=bounding_box[3]\n",
    "        test.append([image, a,b,c,d])\n",
    "    test_df.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C30LssydJ0EV"
   },
   "outputs": [],
   "source": [
    "test=[]\n",
    "for i in test_df:\n",
    "    if len(i)>0:\n",
    "        if len(i)==1:\n",
    "            test.append(i[0])\n",
    "        else:\n",
    "            for j in i:\n",
    "                test.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqR3CkTgO30v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "demo=pd.DataFrame(test)\n",
    "demo.to_csv('/mtcnn',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSJrzh8BKAWC",
    "outputId": "48854d6d-11f0-4851-c693-867f95dd525b"
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veL2s3F1KalW"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcQCj3pRKxrW",
    "outputId": "943c3033-e7e6-4005-bcbe-391b302e0af8"
   },
   "outputs": [],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9Sqe3iXK7hK"
   },
   "outputs": [],
   "source": [
    "sub=[]\n",
    "rest_image=[]\n",
    "for i in test:\n",
    "    sub.append(i[0])\n",
    "for image in test_images:\n",
    "    if image not in sub:\n",
    "        rest_image.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVPzwHULLzs9"
   },
   "outputs": [],
   "source": [
    "test_df_=[]\n",
    "for image in rest_image:\n",
    "    img=cv2.imread(os.path.join('/content/unzipped/Medical mask/Medical Mask/images',image))\n",
    "    faces=detector.detect_faces(img)\n",
    "    test_=[]\n",
    "    for face in faces:\n",
    "        bounding_box=face['box']\n",
    "        test_.append([image,bounding_box])\n",
    "    test_df_.append(test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Certain images displayed an error while cropping them hence the use of exception handling ignored those images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hRUC8-sMrux",
    "outputId": "d2478838-971c-4b5c-89b7-9db66cd4d3da"
   },
   "outputs": [],
   "source": [
    "listt=[]\n",
    "anss=[]\n",
    "images_names=[]\n",
    "coordinates=[]\n",
    "for i in test:\n",
    "  try:\n",
    "      for j in i:\n",
    "          listt.append(j)\n",
    "      s=listt[0]\n",
    "      x=listt[1]\n",
    "      y=listt[2]\n",
    "      w=listt[3]\n",
    "      h=listt[4]\n",
    "      coordinates.append([x,y,x+w,y+h])\n",
    "      listt.clear()\n",
    "      img=plt.imread(os.path.join('/content/unzipped/Medical mask/Medical Mask/images',s))\n",
    "      output=img[y:y+h,x:x+w]\n",
    "      output=cv2.resize(output,(150,150))\n",
    "      anss.append(output)\n",
    "      images_names.append(s)\n",
    "  except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r61MI4e6UgZA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ansss=np.array(anss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGcNG8w-kyNI"
   },
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrO5uGEqUo6S"
   },
   "outputs": [],
   "source": [
    "op=model.predict(ansss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPPiNBPNU8NU"
   },
   "outputs": [],
   "source": [
    "oppp=np.round(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IP4ZPZA7Vg-V"
   },
   "outputs": [],
   "source": [
    "opp=pd.DataFrame(data=oppp,columns=['classname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P13hu5m3Vw1s",
    "outputId": "25bbbdf3-b73d-4df4-83fe-e1a9f0d0da6b"
   },
   "outputs": [],
   "source": [
    "opp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBqX9B96Vj0-",
    "outputId": "9d30595f-546a-4382-9073-c213e99f348b"
   },
   "outputs": [],
   "source": [
    "opp['classname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzwO-pkyZzpa",
    "outputId": "8f2351b1-55d5-4f3b-c8ba-f4ceea59c3df"
   },
   "outputs": [],
   "source": [
    "opp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcNL4a3SasY1"
   },
   "outputs": [],
   "source": [
    "opp.replace(0.0,'face_no_mask',inplace=True)\n",
    "opp.replace(1.0,'face_with_mask',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QwOR74PbN4p",
    "outputId": "ad0b2432-15c7-431f-8a5b-2b86736cc4aa"
   },
   "outputs": [],
   "source": [
    "opp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaURhjKVbYOH",
    "outputId": "d8d5a3fd-d4c1-4e9c-92eb-c47b9f34a9dd"
   },
   "outputs": [],
   "source": [
    "opp['classname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIeGOpG5cf0c"
   },
   "outputs": [],
   "source": [
    "names=pd.DataFrame(images_names,columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPFGlAZKdE7_"
   },
   "outputs": [],
   "source": [
    "coordinates=pd.DataFrame(coordinates,columns=['x1','y1','x2','y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3qpntnVelq1",
    "outputId": "46dbe76c-ea05-41ff-815d-25f289e3048a"
   },
   "outputs": [],
   "source": [
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drJbOTZMgxn3"
   },
   "outputs": [],
   "source": [
    "new=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbRInDf_g4nn"
   },
   "outputs": [],
   "source": [
    "new['name']=names['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu9sUWY2g7jE"
   },
   "outputs": [],
   "source": [
    "new['x1']=coordinates['x1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3Y6YwF7hBXy"
   },
   "outputs": [],
   "source": [
    "new['y1']=coordinates['y1']\n",
    "new['x2']=coordinates['x2']\n",
    "new['y2']=coordinates['y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTpOdbXphSWG"
   },
   "outputs": [],
   "source": [
    "new['classname']=opp['classname']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inverting the list as per the output csv format requirement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPaFa81ChaU2"
   },
   "outputs": [],
   "source": [
    "new=new.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGQZAeIDh7Vu",
    "outputId": "f581d66a-2bf6-4f53-ad9b-44e5eb83ef67"
   },
   "outputs": [],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGhRSFjWiEq0"
   },
   "outputs": [],
   "source": [
    "new.to_csv('/final_submition.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpIHaGVjiv06"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
